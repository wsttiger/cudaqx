/****************************************************************-*- C++ -*-****
 * Copyright (c) 2026 NVIDIA Corporation & Affiliates.                         *
 * All rights reserved.                                                        *
 *                                                                             *
 * This source code and the accompanying materials are made available under    *
 * the terms of the Apache License 2.0 which accompanies this distribution.    *
 ******************************************************************************/

#pragma once

#include "cudaq/qec/realtime/ai_decoder_service.h"
#include <cuda/atomic>
#include <atomic>

// Portable CPU Yield Macro for busy-polling
#if defined(__x86_64__)
    #include <immintrin.h>
    #define QEC_CPU_RELAX() _mm_pause()
#elif defined(__aarch64__)
    #define QEC_CPU_RELAX() asm volatile("yield" ::: "memory")
#else
    #define QEC_CPU_RELAX() std::atomic_thread_fence(std::memory_order_seq_cst)
#endif

namespace cudaq::qec {

struct PreDecoderJob {
    int slot_idx;              ///< Worker/slot index (for release_job; always 0)
    int origin_slot;           ///< FPGA ring slot for tx_flags routing (dynamic pool)
    void* ring_buffer_ptr;
    void* inference_data;      ///< Points into the pinned output (single slot)
};

class AIPreDecoderService : public AIDecoderService {
public:
    AIPreDecoderService(const std::string& engine_path, void** device_mailbox_slot,
                        int queue_depth = 1, const std::string& engine_save_path = "");
    virtual ~AIPreDecoderService();

    void capture_graph(cudaStream_t stream, bool device_launch);
    void capture_graph(cudaStream_t stream) override { capture_graph(stream, true); }

    bool poll_next_job(PreDecoderJob& out_job);
    void release_job(int slot_idx);

    /// Stub for device-dispatcher batch path (returns nullptr; streaming uses host dispatcher)
    int* get_device_queue_idx() const { return nullptr; }
    cuda::atomic<int, cuda::thread_scope_system>* get_device_ready_flags() const { return d_ready_flags_; }
    int* get_device_inflight_flag() const { return nullptr; }

    cuda::atomic<int, cuda::thread_scope_system>* get_host_ready_flags() const { return h_ready_flags_; }
    volatile int* get_host_queue_idx() const { return nullptr; }
    int get_queue_depth() const { return queue_depth_; }

private:
    int queue_depth_;  // Always 1

    cuda::atomic<int, cuda::thread_scope_system>* h_ready_flags_ = nullptr;
    void** h_ring_ptrs_ = nullptr;
    void* h_outputs_ = nullptr;

    cuda::atomic<int, cuda::thread_scope_system>* d_ready_flags_ = nullptr;
    void** d_ring_ptrs_ = nullptr;
    void* d_outputs_ = nullptr;
};

} // namespace cudaq::qec
